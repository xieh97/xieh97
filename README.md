# Hello World! :wave: I'm Huang Xie (谢晃)

> "Science is an error-correcting process."
> 
> — Charles S. Peirce


## :sparkles: About Me

I am a PhD student specializing in **Machine Learning and Signal Processing**, with a research focus on **Audio-Language Learning**, **Audio Information Retrieval**, and **Audio Content Analysis**.
My work explores topics such as _contrastive learning_, _zero-shot learning_, _multimodal learning_, _language-based audio retrieval_, and _audio classification_.
My full resume can be found [here](https://github.com/xieh97/xieh97/blob/main/assets/CV.pdf).


## :fire: Research Interests

- **Audio-Language Learning** focuses on developing systems that integrate audio signals with natural language, enabling seamless interpretation and interaction between these modalities. It employs deep learning, transformer models, and multimodal alignment strategies to map audio features to textual representations. Common applications include audio captioning, spoken language understanding, language-based audio retrieval, and audio question answering.
- **Audio Information Retrieval** involves analyzing and retrieving unstructured information from large-scale audio datasets. It leverages signal processing, feature extraction, machine learning, and indexing methods to organize and search audio content efficiently. Key applications include music recommendation, sound classification, similarity-based retrieval, and audio fingerprinting.
- **Audio Content Analysis** focuses on extracting meaningful patterns and insights from audio signals. It utilizes signal decomposition, feature extraction, deep learning, and statistical modeling to analyze different sound components. It enables tasks like speech recognition, sound event detection, audio sentiment analysis, and music genre classification.


## :dart: Tech and Interests

- :game_die: **Machine Learning / Deep Learning** ([PyTorch](https://pytorch.org/), [MLflow](https://mlflow.org/), [Ray Tune](https://docs.ray.io/en/latest/tune/index.html), [scikit-learn](https://scikit-learn.org/), etc.)
- :chart_with_upwards_trend: **Data Analysis** ([NumPy](https://numpy.org/), [SciPy](https://scipy.org/), [Pandas](https://pandas.pydata.org/), etc.)
- :memo: **Audio & Text Analysis** ([Librosa](https://librosa.org/), [NLTK](https://www.nltk.org/), etc.)
- :bar_chart: **Visualization** ([Matplotlib](https://matplotlib.org/), etc.)
- :rocket: **Software Development** ([Django](https://www.djangoproject.com/), [Spring](https://spring.io/), [Hibernate](https://hibernate.org/), etc.)
- :computer: **Programming** (Python, Java, JavaScript, SQL, etc.)


## :books: Publications

- :page_with_curl: **H. Xie**, K. Khorrami, O. Räsänen and T. Virtanen, "Text-Based Audio Retrieval by Learning From Similarities Between Audio Captions," in IEEE Signal Processing Letters, vol. 32, pp. 221-225, 2025, doi: 10.1109/LSP.2024.3511414. :fire::fire::fire:
- :page_with_curl: **H. Xie**, K. Khorrami, O. Räsänen, and T. Virtanen, "Integrating Continuous and Binary Relevances in Audio-Text Relevance Learning," in Proc. Detect. Classif. Acoust. Scenes Events Work. (DCASE), 2024, pp. 201-205. [arXiv](https://arxiv.org/abs/2408.14939)
- :page_with_curl: **H. Xie**, K. Khorrami, O. Räsänen, and T. Virtanen, "Crowdsourcing and Evaluating Text-Based Audio Retrieval Relevances," in Proc. Detect. Classif. Acoust. Scenes Events Work. (DCASE), 2023, pp. 226-230. [arXiv](https://arxiv.org/abs/2306.09820)
- :page_with_curl: **H. Xie**, O. Räsänen, and T. Virtanen, "On Negative Sampling for Contrastive Audio-Text Retrieval," in Proc. Int. Conf. Acoustic., Speech and Signal Process. (ICASSP), 2023, pp. 1-5. [arXiv](https://arxiv.org/abs/2211.04070)
- :page_with_curl: **H. Xie**, S. Lipping, and T. Virtanen, "Language-based Audio Retrieval Task in DCASE 2022 Challenge," in Proc. Detect. Classif. Acoust. Scenes Events Work. (DCASE), 2022, pp. 216-220. [arXiv](https://arxiv.org/abs/2206.06108)
- :page_with_curl: **H. Xie**, O. Räsänen, K. Drossos, and T. Virtanen, "Unsupervised Audio-Caption Aligning Learns Correspondences Between Individual Sound Events and Textual Phrases," in Proc. Int. Conf. Acoustic., Speech and Signal Process. (ICASSP), 2022, pp. 8867-8871. [arXiv](https://arxiv.org/abs/2110.02939)
- :page_with_curl: **H. Xie**, O. Räsänen, and T. Virtanen, "Zero-Shot Audio Classification with Factored Linear and Nonlinear Acoustic-Semantic Projections," in Proc. Int. Conf. Acoustic., Speech and Signal Process. (ICASSP), 2021, pp. 326-330. [arXiv](https://arxiv.org/abs/2011.12657)
- :page_with_curl: **H. Xie** and T. Virtanen, "Zero-Shot Audio Classification via Semantic Embeddings," in IEEE/ACM Trans. Audio Speech Lang. Process., vol. 29, pp. 1233-1242, 2021. [arXiv](https://arxiv.org/abs/2011.12133)
- :page_with_curl: **H. Xie** and T. Virtanen, "Zero-Shot Audio Classification Based on Class Label Embeddings," in Proc. Work. Appl. Signal Process. Audio and Acoustic. (WASPAA), 2019, pp. 264-267. [arXiv](https://arxiv.org/abs/1905.01926)


## :trophy: Activities

- :man_scientist: Active reviewer for journals and conferences, including TASLP, SPL, ICASSP, INTERSPEECH, IJCNN, EUSIPCO, WASPAA, and others.
- :technologist: Task coordinator for Language-based Audio Retrieval in DCASE Challenge 2024 ([Task 8](https://dcase.community/challenge2024/task-language-based-audio-retrieval)).
- :technologist: Task coordinator for Automated Audio Captioning and Language-based Audio Retrieval in DCASE Challenge 2023 ([Task 6](https://dcase.community/challenge2023/task-automated-audio-captioning-and-language-based-audio-retrieval)).
- :technologist: Task coordinator for Automated Audio Captioning and Language-based Audio Retrieval in DCASE Challenge 2022 ([Task 6](https://dcase.community/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval)).


## :speech_balloon: Connect with Me

- :email: Drop me an email at huang.xie@outlook.com
