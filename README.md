## ğŸ‘‹ Hi, I'm Huang Xie (è°¢æ™ƒ)

> "Science is an error-correcting process."
> â€” Charles S. Peirce

## ğŸ“ About Me

I'm a doctoral researcher at Tampere University, specializing in **machine learning for audio-language understanding and
multimodal modeling**. My passion is building AI systems that can interpret and respond to sound and language in ways
that bring real-world value.

Before entering research, I spent 7+ years as a **software engineer**, where I gained deep experience in scalable system
design and practical problem-solving. Today, I work at the intersection of **ML research and software engineering**,
combining scientific depth with hands-on development to create robust, efficient AI applications.

## ğŸ§  Research Interests

- ğŸ§ Machine Learning for Audio Understanding (classification, detection, retrieval, generation)
- ğŸ” Self-Supervised Representation Learning
- ğŸ”„ Multimodal Learning (audio + text/vision)
- ğŸ§© Low-Resource Learning (zero-shot, few-shot)

## ğŸ› ï¸ Skills & Tools

- ğŸ’» **Programming**: Python, Java, Scala, JavaScript, SQL, C/C++, R, Matlab, LaTeX, GDScript
- âš›ï¸ **Machine Learning**: PyTorch, TensorFlow, scikit-learn, Ray Tune, MLflow, Spark
- ğŸ—£ï¸ **Audio & NLP**: librosa, torchaudio, NLTK
- ğŸ“Š **Data Analysis**: NumPy, SciPy, Pandas, Jupyter, Matplotlib
- ğŸŒ **Web, Backend & Architectures**: Java EE, Spring, Hibernate, Django, Flask, RESTful APIs, Microservices,
  Event-Driven Architectures
- ğŸ“± **GUI & Game Development**: PySide6, Godot Engine
- ğŸ›¢ï¸ **Databases & DevOps**: MySQL, PostgreSQL, Linux, Docker, Git
- âš™ï¸ **Concurrency & Systems**: Multi-threaded Programming, HPC

## ğŸ§ª Featured Projects

- ğŸ§¬ [Audio-Text Semantic Alignment using Unsupervised Learning](https://github.com/xieh97/audio-text-semantic-alignment)
- ğŸ” [Negative Sampling in Contrastive Learning of Audio-Text Representations](https://github.com/xieh97/contrastive-negative-sampling)
- ğŸ¦» [Subjective Evaluation of Audio-Text Semantic Relevance](https://github.com/xieh97/audio-text-graded-relevance)
- â™»ï¸ [Estimating Audio-Text Semantic Relevance through Audio Captions](https://github.com/xieh97/text-audio-retrieval)
- ğŸŒ [Baseline System for Language-Based Audio Retrieval (Task 6B) in DCASE 2023 Challenge](https://github.com/xieh97/dcase2023-audio-retrieval)
- ğŸŒ [Baseline System for Language-Based Audio Retrieval (Task 6B) in DCASE 2022 Challenge](https://github.com/xieh97/dcase2022-audio-retrieval)

[//]: # (- ğŸ” [**Multimodal Audio-Text Retrieval System**]&#40;https://github.com/xieh97/text-audio-retrieval&#41; â€“ Developing models)
[//]: # (  that match audio clips with text queries using multimodal learning.)
[//]: # (- ğŸ¤– **X-GoBot** â€“ ğŸ”§[WIP] Developing a voice-enabled desktop AI assistant with local processing and contextual awareness.)

## ğŸ’¬ Let's Connect

Happy to discuss **multimodal ML**, **applied AI**, or the challenges of building multimodal AI systems. Whether you're
hacking on a side project, exploring new ideas, or working in research â€” feel free to reach out, I'd love to exchange
thoughts!

ğŸ“« **Email**: huang.xie@outlook.com
ğŸ”— **LinkedIn**: [linkedin.com/in/huang-xie-28b7872bb](https://linkedin.com/in/huang-xie-28b7872bb/)
