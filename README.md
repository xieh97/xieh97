# Hello World! :wave: I'm Huang Xie (谢晃)

> "Science is an error-correcting process."
> 
> — Charles S. Peirce


## :sparkles: About Me

I am a PhD student specializing in **Machine Learning and Signal Processing**, with a research focus on **Audio Understanding**, **Audio-Language Multimodal Learning**, and **Audio Information Retrieval**.
My work explores topics such as _self-supervised learning_, _contrastive learning_, _zero-shot learning_, _multimodal learning_, _language-based audio retrieval_, and _audio classification_.
My full resume can be found [here](https://github.com/xieh97/xieh97/blob/main/assets/CV.pdf).


## :fire: Research Interests

- **Audio Understanding** refers to the process of analyzing and interpreting audio signals to extract meaningful information. It involves various tasks such as speech recognition, sound event detection, music analysis, and speaker identification. The goal is to enable machines to comprehend and process auditory data in a way similar to human perception.
- **Audio-Language Multimodal Learning** is a field of study that focuses on integrating both audio and textual (or spoken) information for machine learning applications. This involves training models to process and correlate audio signals (such as speech, sounds, or music) with textual data (such as captions, transcripts, or semantic labels). It is used in tasks like automatic subtitle generation, speech-to-text translation, and audio question answering.
- **Audio Information Retrieval** is the process of indexing, searching, and retrieving audio content based on queries, which can be textual, acoustic, or semantic. It encompasses techniques such as music retrieval, sound classification, and spoken document retrieval. The aim is to develop efficient methods for organizing and accessing large-scale audio databases.


## :dart: Tech and Interests

- :game_die: **Machine Learning / Deep Learning** ([PyTorch](https://pytorch.org/), [MLflow](https://mlflow.org/), [Ray Tune](https://docs.ray.io/en/latest/tune/index.html), [scikit-learn](https://scikit-learn.org/), etc.)
- :chart_with_upwards_trend: **Data Analysis** ([NumPy](https://numpy.org/), [SciPy](https://scipy.org/), [Pandas](https://pandas.pydata.org/), etc.)
- :memo: **Audio & Text Analysis** ([Librosa](https://librosa.org/), [NLTK](https://www.nltk.org/), etc.)
- :bar_chart: **Visualization** ([Matplotlib](https://matplotlib.org/), etc.)
- :rocket: **Software Development** ([Django](https://www.djangoproject.com/), [Spring](https://spring.io/), [Hibernate](https://hibernate.org/), etc.)
- :computer: **Programming** (Python, Java, JavaScript, SQL, etc.)


## :books: Publications

- :page_with_curl: **H. Xie**, K. Khorrami, O. Räsänen and T. Virtanen, "Text-Based Audio Retrieval by Learning From Similarities Between Audio Captions," in IEEE Signal Processing Letters, vol. 32, pp. 221-225, 2025, doi: 10.1109/LSP.2024.3511414. :fire::fire::fire:
- :page_with_curl: **H. Xie**, K. Khorrami, O. Räsänen, and T. Virtanen, "Integrating Continuous and Binary Relevances in Audio-Text Relevance Learning," in Proc. Detect. Classif. Acoust. Scenes Events Work. (DCASE), 2024, pp. 201-205. [arXiv](https://arxiv.org/abs/2408.14939)
- :page_with_curl: **H. Xie**, K. Khorrami, O. Räsänen, and T. Virtanen, "Crowdsourcing and Evaluating Text-Based Audio Retrieval Relevances," in Proc. Detect. Classif. Acoust. Scenes Events Work. (DCASE), 2023, pp. 226-230. [arXiv](https://arxiv.org/abs/2306.09820)
- :page_with_curl: **H. Xie**, O. Räsänen, and T. Virtanen, "On Negative Sampling for Contrastive Audio-Text Retrieval," in Proc. Int. Conf. Acoustic., Speech and Signal Process. (ICASSP), 2023, pp. 1-5. [arXiv](https://arxiv.org/abs/2211.04070)
- :page_with_curl: **H. Xie**, S. Lipping, and T. Virtanen, "Language-based Audio Retrieval Task in DCASE 2022 Challenge," in Proc. Detect. Classif. Acoust. Scenes Events Work. (DCASE), 2022, pp. 216-220. [arXiv](https://arxiv.org/abs/2206.06108)
- :page_with_curl: **H. Xie**, O. Räsänen, K. Drossos, and T. Virtanen, "Unsupervised Audio-Caption Aligning Learns Correspondences Between Individual Sound Events and Textual Phrases," in Proc. Int. Conf. Acoustic., Speech and Signal Process. (ICASSP), 2022, pp. 8867-8871. [arXiv](https://arxiv.org/abs/2110.02939)
- :page_with_curl: **H. Xie**, O. Räsänen, and T. Virtanen, "Zero-Shot Audio Classification with Factored Linear and Nonlinear Acoustic-Semantic Projections," in Proc. Int. Conf. Acoustic., Speech and Signal Process. (ICASSP), 2021, pp. 326-330. [arXiv](https://arxiv.org/abs/2011.12657)
- :page_with_curl: **H. Xie** and T. Virtanen, "Zero-Shot Audio Classification via Semantic Embeddings," in IEEE/ACM Trans. Audio Speech Lang. Process., vol. 29, pp. 1233-1242, 2021. [arXiv](https://arxiv.org/abs/2011.12133)
- :page_with_curl: **H. Xie** and T. Virtanen, "Zero-Shot Audio Classification Based on Class Label Embeddings," in Proc. Work. Appl. Signal Process. Audio and Acoustic. (WASPAA), 2019, pp. 264-267. [arXiv](https://arxiv.org/abs/1905.01926)


## :trophy: Activities

- :man_scientist: Active reviewer for journals and conferences, including TASLP, SPL, ICASSP, INTERSPEECH, IJCNN, EUSIPCO, WASPAA, and others.
- :technologist: Task coordinator for Language-based Audio Retrieval in DCASE Challenge 2024 ([Task 8](https://dcase.community/challenge2024/task-language-based-audio-retrieval)).
- :technologist: Task coordinator for Automated Audio Captioning and Language-based Audio Retrieval in DCASE Challenge 2023 ([Task 6](https://dcase.community/challenge2023/task-automated-audio-captioning-and-language-based-audio-retrieval)).
- :technologist: Task coordinator for Automated Audio Captioning and Language-based Audio Retrieval in DCASE Challenge 2022 ([Task 6](https://dcase.community/challenge2022/task-automatic-audio-captioning-and-language-based-audio-retrieval)).


## :speech_balloon: Connect with Me

- :email: Drop me an email at huang.xie@outlook.com
