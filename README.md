## 👋 Hi, I'm Huang Xie (谢晃)
> "Science is an error-correcting process."
> — Charles S. Peirce

## 🎓 About Me
I'm a doctoral researcher at Tampere University, specializing in **machine learning for audio understanding**. I'm passionate about teaching machines to hear, interpret, and respond to sound like humans do.

Before entering research, I spent over 7 years as a software engineer, giving me a strong foundation in building scalable systems and solving real-world problems. I now work at the intersection of **ML research**, **software engineering**, and **AI-driven audio applications**, combining scientific depth with hands-on development skills.

## 🧠 Research Interests
- 🎧 Machine Learning for Audio Understanding (classification, detection, retrieval, generation)
- 🔍 Self-Supervised Representation Learning
- 🔄 Multimodal Learning (audio + text/vision)
- 🧩 Low-Resource Learning (zero-shot, few-shot)

## 🛠️ Skills & Tools
- 💻 **Programming**: Python, Java, Scala, Kotlin, C/C++, GDScript, JavaScript, SQL, HTML/CSS, R, Matlab, LaTeX
- ⚛️ **ML & Data**: PyTorch, TensorFlow, scikit-learn, Ray Tune, MLflow, Spark, NumPy, SciPy, Pandas, Jupyter
- 🗣️ **Audio & NLP**: librosa, torchaudio, NLTK
- 🌐 **Web & Backend**: Java EE, Spring, Hibernate, Django, Flask
- ⚙️ **Databases & DevOps**: MySQL, PostgreSQL, Docker, Git, Linux, HPC

## 🧪 Featured Projects
- 🔎 [**Multimodal Audio-Text Retrieval System**](https://github.com/xieh97/text-audio-retrieval) – Developing models that match audio clips with text queries using multimodal learning.
- 🤖 **X-GoBot** – 🔧[WIP] Developing a voice-enabled desktop AI assistant with local processing and contextual awareness.

## 💬 Let's Connect
I'm always open to conversations about **audio ML**, **applied AI**, or building smart, sound-aware systems. Whether you're in research, industry, or tinkering with side projects — feel free to reach out!

📫 **Email**: huang.xie@outlook.com  
🔗 **LinkedIn**: [linkedin.com/in/huang-xie-28b7872bb](https://linkedin.com/in/huang-xie-28b7872bb/)
